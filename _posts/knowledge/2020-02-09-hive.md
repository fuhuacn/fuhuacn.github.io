---
layout: post
title: Hive 技术原理解析
categories: Knowledge
description: Hive 技术原理解析理分析
keywords: HIVE,架构原理
---
[参考来源](https://blog.csdn.net/wangyang1354/article/details/50570903)

目录

* TOC
{:toc}

# HIVE 定义

Hive 是建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。Hive 定义了简单的类 SQL 查询语言，称为 HQL，它允许熟悉 SQL 的用户查询数据。同时，这个语言也允许熟悉 MapReduce 开发者的开发自定义的 mapper 和 reducer 来处理内建的 mapper 和 reducer 无法完成的复杂的分析工作。

Hive 构建在基于静态批处理的 Hadoop 之上，Hadoop 通常都有较高的延迟并且在作业提交和调度的时候需要大量的开销。因此，Hive 并不能够在大规模数据集上实现低延迟快速的查询，例如，Hive 在几百 MB 的数据集上执行查询一般有分钟级的时间延迟。
Hive 并不适合那些需要低延迟的应用，例如，联机事务处理（OLTP）。Hive 查询操作过程严格遵守Hadoop MapReduce 的作业执行模型，Hive 将用户的HiveQL 语句通过解释器转换为MapReduce 作业提交到Hadoop 集群上，Hadoop 监控作业执行过程，然后返回作业执行结果给用户。Hive 并非为联机事务处理而设计，Hive 并不提供实时的查询和基于行级的数据更新操作。Hive 的最佳使用场合是大数据集的批处理作业，例如，网络日志分析。

# HIVE 与 Hadoop 的关系

Hive 的执行入口是 Driver，执行的 SQL 语句首先提交到 Drive 驱动，然后调用 compiler 解释驱动，最终解释成 MapReduce 任务去执行。

![HIVE架构图](/images/posts/knowledge/hive/20160123184241450.png)

# HIVE 组件

1. Driver 组件：该组件包括：Compiler、Optimizer（优化）、Executor，它可以将 Hive 的编译、解析、优化转化为 MapReduce 任务提交给 Hadoop1 中的 JobTracker 或者是 Hadoop2 中的 SourceManager 来进行实际的执行相应的任务。

2. MetaStore 组件：存储着 hive 的元数据信息，将自己的元数据存储到了关系型数据库当中，支持的数据库主要有：Mysql 支持把 metastore 独立出来放在远程的集群上面，使得 hive 更加健壮。元数据主要包括了表的名称、表的列、分区和属性、表的属性（是不是外部表等等）、表的数据所在的目录。

3. 用户接口：CLI（Command Line Interface)(常用的接口：命令行模式）、Client：Hive 的客户端用户连接至 Hive Server，在启动 Client 的时候，需要制定 Hive Server 所在的节点，并且在该节点上启动 Hive Server 通过浏览器的方式访问 Hive。

# HIVE 的工作流程

![HIVE流程图](/images/posts/knowledge/hive/20160123191344049.jpeg)

流程大致步骤为：

1. 用户提交查询等任务给 Driver。
2. 编译器获得该用户的任务 Plan。
3. 编译器 Compiler 根据用户任务去 MetaStore 中获取需要的 Hive 的元数据信息。
4. 编译器 Compiler 得到元数据信息，对任务进行编译，先将 HiveQL 转换为抽象语法树，然后将抽象语法树转换成查询块，将查询块转化为逻辑的查询计划，重写逻辑查询计划，将逻辑计划转化为物理的计划（MapReduce）, 最后选择最佳的策略。
5. 将最终的计划提交给 Driver。
6. Driver 将计划 Plan 转交给 ExecutionEngine 去执行，获取元数据信息，提交给 JobTracker 或者 SourceManager 执行该任务，任务会直接读取 HDFS 中文件进行相应的操作。
7. 获取执行的结果。
8. 取得并返回执行结果。

# HIVE 的编译优化

基本流程为：将 HiveQL 转化为抽象语法树再转为查询块然后转为逻辑查询计划再转为物理查询计划最终选择最佳决策的过程。

优化器的主要功能：

1. 将多 Multiple join 合并为一个 Muti-way join
2. 对 join、group-by 和自定义的 MapReduce 操作重新进行划分。
3. 消减不必要的列。
4. 在表的扫描操作中推行使用断言。
5. 对于已分区的表，消减不必要的分区。
6. 在抽样查询中，消减不必要的桶。
7. 优化器还增加了局部聚合操作用于处理大分组聚合和增加再分区操作用于处理不对称的分组聚合。

![HIVE编译](/images/posts/knowledge/hive/20160123205210212.png)

# HIVE 的数据类型

Hive 支持原子和复杂数据类型，原子数据类型包括：数据值、布尔类型、字符串类型等，复杂的类型包括：Array、Map 和 Struct。其中 Array 和 Map 和 java 中的 Array 和 Map 是相似的，Struct 和 C 语言中的 Struct 相似。

例如：

``` sql
Create table test(
col1 Array<int>,
col2 Map<String,int>,
col3 Struct<a:String,b:int,c:Double>
);
```

![数据类型](/images/posts/knowledge/hive/20160123205651152.png)

注：

1. 原子数据类型是可以进行隐式的转换的，例如 tinyInt 类型会自动转为 Int 类型但是不能由 Int 自动转为 tinyInt 类型。
2. 所有的整数类型、Float 和 String 类型都可以转换为 Double 类型。
3. TinyInt、SmallInt、Int 都可以转为 Float 类型。
4. Boolean 类型不可以转换为其他的任何类型。
5. 可以通过使用 Cast 操作显示的进行数据转换，例如 Cast('1' as int); 将字符串转为整型，如果强制转换失败如： Cast('X' as int); 表达式返回的是 NULL;

# HIVE 客户端

HIVE CLI（HIVE 命令）缺乏安全性、多用户性等特点，现在被 beeline 和 hiveserver2 废弃掉了。